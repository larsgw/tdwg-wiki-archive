head	1.16;
access;
symbols;
locks; strict;
comment	@# @;


1.16
date	2008.10.18.14.50.04;	author GregWhitbread;	state Exp;
branches;
next	1.15;

1.15
date	2008.10.15.14.59.39;	author KathiSchleidt;	state Exp;
branches;
next	1.14;

1.14
date	2008.10.15.10.47.19;	author RogerHyam;	state Exp;
branches;
next	1.13;

1.13
date	2008.10.13.14.35.16;	author KathiSchleidt;	state Exp;
branches;
next	1.12;

1.12
date	2008.10.13.13.00.49;	author BobMorris;	state Exp;
branches;
next	1.11;

1.11
date	2008.10.13.11.30.55;	author RogerHyam;	state Exp;
branches;
next	1.10;

1.10
date	2008.10.13.10.03.46;	author RogerHyam;	state Exp;
branches;
next	1.9;

1.9
date	2008.09.30.14.19.57;	author RogerHyam;	state Exp;
branches;
next	1.8;

1.8
date	2008.09.30.10.01.46;	author RogerHyam;	state Exp;
branches;
next	1.7;

1.7
date	2008.09.29.16.10.40;	author RogerHyam;	state Exp;
branches;
next	1.6;

1.6
date	2008.09.29.13.59.08;	author RogerHyam;	state Exp;
branches;
next	1.5;

1.5
date	2008.09.29.12.29.47;	author RogerHyam;	state Exp;
branches;
next	1.4;

1.4
date	2008.09.26.11.11.25;	author RogerHyam;	state Exp;
branches;
next	1.3;

1.3
date	2008.09.05.16.06.58;	author RenatoDeGiovanni;	state Exp;
branches;
next	1.2;

1.2
date	2008.08.08.01.22.10;	author KevinRichards;	state Exp;
branches;
next	1.1;

1.1
date	2008.08.05.09.29.11;	author RogerHyam;	state Exp;
branches;
next	;


desc
@none
@


1.16
log
@none
@
text
@%META:TOPICINFO{author="GregWhitbread" date="1224341404" format="1.1" version="1.16"}%
%META:TOPICPARENT{name="RoadMap2007"}%
---+ <nop>%TOPIC%

The stated strategy of the Technical Architecture Group is to:

 _"Produce a yearly review and forecast of technical issues within TDWG prior to the annual meeting - The Roadmap."_

This page was  used to develop the 2008 Roadmap document. This work is now complete. If you need to see how it progressed you can look at the change history for this page.

The finished document is now available as a PDF file: [[%ATTACHURL%/TDWG_TAG_Roadmap_2008.pdf][TDWG_TAG_Roadmap_2008.pdf]]

Roadmaps were also produced for 
[[http://wiki.tdwg.org/twiki/pub/TAG/ArchitectureOverview/roadmap_04.doc][2006]] and
[[http://wiki.tdwg.org/twiki/pub/TAG/RoadMap2007/TAG_Roadmap_2007_final.pdf][2007]].

---++ Agenda for TAG Meeting in Fremantle 

Sunday 19th October 2008 0900-1300 Notre Dame University Education Centre room 36.103 (seats 45) 

See the conference site on how to find this stuff http://www.tdwg.org/conference2008/

   * LSIDs - Adopting a realistic position on adoption?
   * Design By Consensus == collective wisdom of individual ignorance - discuss.
   * Ontology - How we going to manage this thing?
   * Delimited Files - How do we ensure they are integrated with everything else?
   * Convener - How are we ever going to replace Roger? :)

---++ Attendees
This is an open meeting but it would be helpful if you would add your name below so we know who to expect.
   * RogerHyam
   * KathiSchleidt
   * GregWhitbread
   * Please add your name here...

----
%SEARCH{"%TOPIC%" excludetopic="%TOPIC%" header="*Linking Topics*" format="   * $topic" nosearch="on" nototal="on" }%


%META:FILEATTACHMENT{name="TDWG_TAG_Roadmap_2008.pdf" attachment="TDWG_TAG_Roadmap_2008.pdf" attr="" comment="TDWG TAG Roadmap 2008" date="1224066888" path="TDWG_TAG_Roadmap_2008.pdf" size="107665" stream="TDWG_TAG_Roadmap_2008.pdf" user="Main.RogerHyam" version="1"}%
@


1.15
log
@none
@
text
@d1 1
a1 1
%META:TOPICINFO{author="KathiSchleidt" date="1224082779" format="1.1" version="1.15"}%
d33 1
@


1.14
log
@none
@
text
@d1 1
a1 1
%META:TOPICINFO{author="RogerHyam" date="1224067639" format="1.1" reprev="1.14" version="1.14"}%
d32 1
@


1.13
log
@none
@
text
@d1 1
a1 1
%META:TOPICINFO{author="KathiSchleidt" date="1223908516" format="1.1" version="1.13"}%
d9 5
a13 1
This page is being used to develop the 2008 Roadmap document. Roadmaps were also produced for 
d17 1
a17 5
----
Text below here constitutes the document so if you add comments flag them well so they don't end up in the final document! Discuss stuff on the TDWG TAG mailing list if needed.
----
_What is a system? A system is a network of interdependent components that work together to try to accomplish the aim of the system. A system must have an aim. Without an aim, there is no system. The aim of the system must be clear to everyone in the system. The aim must include plans for the future. The aim is a value judgment._ (William Edwards Deming)
----
d19 1
a19 1
%TOC%
d21 1
a21 3
---++ Introduction 
The Technical Architecture Group of the Biodiversity Information Standards (TDWG) is charged with maintaining an overview of TDWG standards, their relationships to each other and to standards produced by other organisations. The charter of the TAG states 
that a yearly report will  be produced called the 'Roadmap'. This is the 2008 Roadmap document. It supersedes the 2007 Roadmap presented in Bratislava and the 2006 Roadmap presented at the St Louis. Previous roadmaps are available on the TDWG website.
d23 10
a32 1
The reader is referred the [[http://wiki.tdwg.org/twiki/bin/viewfile/TAG/RoadMap2007?rev=1;filename=TAG_Roadmap_2007_final.pdf][2007 Roadmap]] for a fuller justification for the architecture and summary of all historical TDWG standards.
d34 2
a35 46
---++ Summary of Architecture
The following is produced verbatim from last years roadmap as an introductory overview to the architecture.

---+++ Why have a standards architecture?
From the point of view of exchanging data &#8211; such as in the federation of a number of natural history collections &#8211; there is no need for a standards architecture. The federation is a closed system where a single exchange format can be agreed on. The federation can grow by adding new members whose needs are met by the format. This model has worked well in the past but it does not meet the primary use case that is emerging. Biodiversity research is typically carried out by combining data of different kinds from multiple sources. The providers of data do not know who will use their data or how it will be combined with data from other sources. The consumer needs some level of commonality across all the data received so that it can be combined for analysis without the need to write computer software for every new combination. This commonality needs to seamlessly extend to new types of data as they are made available. An architecture is required to provided this commonality.

---+++ What form should the architecture take?
A degree of commonality could be achieved simply by specifying how data should be serialised. If all suppliers passed data as well-formed XML, for example, it would provide a degree of interoperability but clients would still not know how the elements within one XML document relate to those in another or how the items described in those documents were related. At the other extreme, the architecture could provide a detailed data type library which described the way in which each kind of data should be serialised at a fine level of granularity &#8211; which XML elements must be present and what they should contain &#8211; but it is highly unlikely that a single set of serialisations would meet all needs any more than a single federation schema would. It remains a requirement of some thematic networks that they have well defined data types to ensure that the data passed is valid and fit for purpose.

The architecture therefore has to meet two needs. It has to allow generic interoperability but also restricted validation of data for some networks. It does this by taking a three pronged approach.
   1) An ontology is used to express the shared semantics of the data but not to define the validity of that data. Concepts within the ontology are represented as URIs (Universal Resource Identifiers).
   2) Exchange protocols use formats defined in XML Schema (or other technologies) that exploit the URIs from the ontology concepts.
   3) Objects about which data is exchanged are identified using Globally Unique Identifiers.

This means that (although exchanges between data producers and clients may make use of different XML formats) the items the data is about and the meaning of the data elements is common across all formats.

---++ Globally Unique Identifiers (GUIDs)

GUIDs are a key component of the architecture because they solve two main problems:

   * *Multiple Routes* In an environment where information is shared freely a client (either machine or person) may receive the same piece of data via different routes and believe it has received multiple pieces of data. One piece of data may say that species A occurs at longitude X and latitude Y and another may say A occurs at long. X lat. Y with a error of 1km. Even if both these pieces of data have been retrieved from the same data source there is no way of knowing if they are referring to the same  or separate measurements of the real world. i.e. Do they add to our confidence that A occurs at X,Y or not? Only if the two pieces of data are given identities by their originators (and linked back to their sources should they be derived) can we track whether these are the same piece of data or derived from a common piece of data or even from each other. The requirement for GUIDs is clear even without defining what constitutes a valid "piece of data". Without GUIDs it is hard to know how much biodiversity data is in circulation, and claims should be treated with caution.
   * *Ownership and Trust*  This is closely related to the multiple routes problem. When a client (either machine or person) receives a piece of data how do they know whether it has been 'corrupted' or 'improved' by a third party? Whether it is up to date or whether it has been updated or deprecated? How do they know what they can legally do with it in terms of disseminating it and, most importantly, how do they credit the producers of the data? The simplest and only workable solution to this problem is for the piece of data to carry with it a means of retrieving a clean copy of itself and any associated legal metadata. Tagging the data with a resolvable (i.e., can be dereferenced) GUID allows this to happen. The most familiar example of such a GUID is the URL of a web page. A client may receive a printed or cached web page but can always get back to the original version by calling its URL.

These points and others were discussed during a series of international workshops and meetings over the last three years that resulted in a proposal to adoption Life Science Identifiers (LSIDs) as the preferred technology for GUIDs. The details of the use of LSIDs are outlined in the LSID applicability statement that is currently proposed as a TDWG standard.

The TDWG architecture does not mandate the use of LSIDs. The only requirements of GUIDs is that they really are globally unique and that they are resolvable, ideally through standard web technologies such as HTTP. The LSID applicability statements recommends the use of an HTTP proxy for LSIDs which makes them behave much like regular URLs. Similar proxy approaches are taken with other GUID technologies such as DOI and older standards such as ISBN or non-resolvable GUIDs, such as Universally Unique Identifier (UUIDs).

---+++ GUID Challenges

Adoption of GUIDs is the single most important requirement to improve the quality of biodiversity data exchange and yet data suppliers do not appear to be adopting them with any sense of urgency. Primary reasons for this are:
   * Lack of knowledge understandably caused by seeing the problem from a data suppliers point of view rather than as the consumer of data from multiple sources.
   * Lack of permanent internal identifiers for data. e.g. they may rely on database primary keys that are changed during database migrations but which don't affect their internal working processes - a spreadsheet mentality to data.
   * Lack of the awareness of the primary benefit to the data supplier of tagging data with GUIDs e.g., the ability of users to cite their sources and give credit even when data from multiple sources has been used in an analysis.
   * Confusion over GUID standards. There are a series of competing standards and there has been much open debate as to which to adopt. This even includes confusion within standards on how they should be implemented e.g., data return types.
   * Difficulty in implementing LSIDs. LSIDs require the addition of a special DNS rule to the name server that controls the institution's domain name. Data curators may not have access to this name server or even know what a name server is, let alone how to change it. This is a major barrier to LSIDs adoption.
   * Difficulty in implementing any resolvable identifier - even the URL to a web page. Many institutions have corporately managed web sites and it is no simple matter for data curators to add database-driven content, even if they have the skills and applications/tools to hand.

It appears the discussions on GUIDs within TDWG have not addressed the true level of resources available in the community. Barriers to adoption are not principally technical.

---+++ TAG GUID Recommendations to Data Suppliers
   * You must have working practices that maintain locally unique IDs on your data within your databases. If you don't do this you will not be able to expose your data using globally unique IDs now or in the future.
   * Whenever you expose your data you should include GUIDs that can be resolved back to your internal locally unique IDs. Don't get hung up on the technology. If you can't manage LSIDs, some type of URL that your institution can commit to maintaining for the foreseeable future is fine. In simple terms - every 'thing' you expose to the world should be represented by a web 'page'.

---++ Ontology

Ontology is a loaded term with many definitions connected to creating formalisations of reality - a subject that has occupied thinking people for thousands of year. The TDWG ontology is more of a functional thing and, wearing retrospecitcals, the word 'Dictionary' would have been a better one to use although this to has multiple meanings.
a36 1
If GUIDs are used to uniquely identify 'pieces' of data we need to have a shared understanding of what we mean by a 'piece of data' i.e. what kind thing is it that a particular id applies to, a specimen, a person, an observation, a complete data set. We also need to have a shared understanding of at least some of the properties we use to describe these things. This is the function of the TDWG ontology. It is not a expansive formalisation of the biodiversity informatics domain but a rather trivial list of the things that we, as a community, can agree on the meaning of.
d38 1
a38 53
The TDWG Ontology enables the following kind of interaction. A client receives a piece of data such as "Species A occurs at longitude X, latitude Y" that is tagged with a GUID. The client application resolves the GUID back to the originator of the data (just like looking up a web page) and receives the data associated with the GUID. This includes the fact that the GUID is for a type of thing that is a tdwg:Specimen that is located in a particular tdwg:Collection.  On the basis of this client can take appropriate action that may be different from the actions it would have taken if it the GUID had been for a object of the kind tdwg:Observation.

If there are multiple exchange standards (catering to multiple application requirements) that all map to the TDWG Ontology (and other well known vocabularies) using XML namespaces then it is possible for application developers to "cross-walk" between different standards and build useful tools. If exchange standards do not map to the TDWG Ontology then everybody who needs to translate between exchange standards is likely to do it slightly differently and precision will be lost.

---+++ Ontology Challenges

The word ontology is a major challenge as it has dragged the community into hours of discussions concerning RDF, OWL, reification and inference. In so doing we lose sight of the tremendous benefits of having a basic list of shared objects and their properties. 

Even to keep a list of core TDWG concepts up to date, manage the consensus building process around new concepts and educate standards developers in how to integrate the ontology into their proposals is a very time consuming and therefore expensive process. Nobody has been resourced to do this work in 2008 and therefore it hasn't happened as it should. Unless some form of ontology manager is given the resources to curatate this central resource then there is a danger that the expectations of interoperability will not be met.

---+++ TAG Ontology Recommendations
   * Don't get hung up on complex talk of ontologies and inference especially if you are not designing your own exchange formats. The ontology should be thought of as a concept repository for the community not a model of the entire subject domain.
   * If you are working on an exchange format don't make up new concepts if you can help it. Use existing ones from the TDWG ontology, IETF, W3C, Dublin Core etc or at least describe how your concepts match to these.
   * If you are using XML use namespaces correctly so as to exploit other vocabularies. If you can't do this, publish a mapping to well know namespaces.

---++ Exchange Protocols

---+++ TAPIR

The most well developed area of TDWG before the standards architecture was proposed were the exchange protocols DiGIR and BioCASe with their associated federation schemas DarwinCore and ABCD. This momentum has continued with the development of the TAPIR protocol that unifies the DiGIR and BioCASe protocols and also comes closer to the [[http://www.opengeospatial.org/][OGC]]'s [[http://www.opengeospatial.org/standards/wfs][WFS]] protocol. Because TAPIR, in its more complete implementations, allows the specification of output data models it is possible for TAPIR based providers to mimic other types of data provider.

There were two important developments related to TAPIR in the last year. One of them is a new service ([[http://tapir.tdwg.org/tester][TapirTester]]) to test if a TAPIR provider is compliant with the current TAPIR specification. It can be used by those who need to implement new data provider software or by users of data provider software who want to check if their services are working properly. Although TapirTester does not include all possible tests that can be performed, it covers most aspects of the protocol, which makes it an important quality control tool. The new service is available both as a web interface and as a web service.

The other development ([[http://tapir.tdwg.org/builder][TapirBuilder]]) facilitates the creation of TAPIR documents. TAPIR networks depend on specific documents to work: XML Schemas (that can be created by existing tools), output models and query templates. The last two documents are specific to TAPIR and sometimes it can be difficult to produce them by hand. TapirBuilder is a new online tool to help building such documents.

A [[http://rs.tdwg.org/tapir/cns/index.xml][new format]] based on XML was also proposed to represent data abstraction layers for TAPIR (replacing the previous CNS configuration files using key-value pairs in plain text). An index containing some of the existing data abstraction layers is available. There is also discussion on the need to be able to "discover" existing TAPIR models that people develop as these would be useful for other people to reuse, when appropriate.

Current plans are to submit TAPIR to the TDWG standards track by the end of 2008 after final discussions in the TAPIR mailing list.

---+++ Delimited Files

While harvesting completed sets of flat DarwinCore type data for the GBIF data portal it became apparent that the communications using existing TDWG protocols (DiGIR, ABCD and TAPIR) were very verbose, resulting in a large amount of network traffic and database activity to do something that could be achieved in a simpler manner.  Additionally, there are data providers who have either
   * too large a dataset to effectively harvest the full set in one go over existing protocols (months of work)
   * or do not have the ability to install wrapper software on an accessible web server.
For these reasons, it has been decided to support simple delimited files within the GBIF harvesting mechanism, that represent the full dataset, and are produced on the provider side using a simple database export and then compressed for transfer. It is proposed that extensions to simple occurrence records will be supported on a one file per extension basis, whereby the row in the extension file references an identifier in the core file, thereby allowing for "many to one" style extensions. This is effectively creating a relational model.

Importantly an attempt will be made to map the files and the fields within the files to the TDWG ontology and to provide GUID for the rows in the core file. In this way these delimited files will leverage the TDWG architecture for both very large and very small data sets.

This is likely to be an area of active development in 2009.

---+++ REST Services

There has been some discussion on REST ([[http://en.wikipedia.org/wiki/Representational_State_Transfer][Representational State Transfer]]) web services. REST is a style of architecture rather than a specific protocol. Both TAPIR and OAI-PMH could be regarded as RESTful services. Where the REST pattern is not matched by the TDWG architecture is the degree to which GUIDs are not all uniquely addressable using a universal syntax. Both LSIDs and DOIs make use of independent resolution mechanisms. It is therefore recommended, and is common practice, to provide a version of these GUIDs that use HTTP proxy resolution. HTTP should be thought of as the universal syntax for addressable resources.

---+++ TAG Protocol Recommendations
   * If you want to expose data to a particular project follow that particular project's current recommendations. It is the role of the TAG to make recommendations to projects not to individual data suppliers.
   * If you are making the recommendations for a project and have a need for queryable nodes within your network then recommend TAPIR rather than DiGIR or BioCASe.
   * Even if you exchange plain XML documents using TAPIR you should make sure you use GUIDs and map to the TDWG Ontology where possible.
   * If you are making the recommendations for a project and only require a harvesting protocol then consider using OAI-PMH but discuss with the TAG what your metadata formats may be so as to enhance re-use. No one is harvesting with OAI-PMH in our community at the moment.
   * If you are making the recommendations and it is likely that some or all of your data suppliers will not be able to set up and run web services consider participating with Tim Robertson and Markus Doring at GBIF in development of a delimited file standard.

----
%SEARCH{"%TOPIC%" excludetopic="%TOPIC%" header="*Linking Topics*" format="   * $topic" nosearch="on" nototal="on" }%@


1.12
log
@none
@
text
@d1 1
a1 1
%META:TOPICINFO{author="BobMorris" date="1223902849" format="1.1" version="1.12"}%
d78 1
a78 1
If there are multiple exchange standards (catering to multiple application requirements) that all map to the TDWG Ontology (and other well known vocabularies) using XML namespaces then it is possible for application developers to "cross-walk" between different standards and build useful tools. If exchange standard do not to the TDWG Ontology then everybody who needs to translate between exchange standards is likely to do it slightly differently and precision will be lost.
@


1.11
log
@none
@
text
@d1 1
a1 1
%META:TOPICINFO{author="RogerHyam" date="1223897455" format="1.1" reprev="1.11" version="1.11"}%
d47 2
a48 2
   * *Multiple Routes* In an environment where information is shared freely a client (either machine or person) may receive the same piece of data via different routes and believe it has received multiple pieces of data. One piece of data may say that species A occurs at longitude X and latitude Y and another may say A occurs at long. X lat. Y with a error of 1km. Even if both these pieces of data have been retrieved from the same data source there is no way of knowing if they are referring to the same  or separate measurements of the real world. i.e. Do they add to our confidence that A occurs at X,Y or not? Only if the two pieces of data are given identities by their originators (and linked back to their sources should they be derived) can we track whether these are the same piece of data or derived from a common piece of data or even from each other. The requirement for GUIDs is clear even without defining what constitutes a valid "piece of data". Without GUIDs it is had to know how much biodiversity data is in circulation and claims should be treated with caution.
   * *Ownership and Trust*  This is closely related to the multiple routes problem. When a client (either machine or person) receives a piece of data how do they know whether it has been 'corrupted' or 'improved' by a third party? Whether it is up to date or whether it has been updated or deprecated? How do they know what they can legally do with it in terms of disseminating it and, most importantly, how do they credit the producers of the data? The simplest and only workable solution to this problem is for the piece of data to carry with it a means of retrieving a clean copy of itself and any associated legal metadata. Tagging the data with a resolvable (can be dereferenced) GUID allows this to happen. The most familiar example of such a GUID is the URL of a web page. A client may receive a printed or cached web page but can always get back to the original version by calling its URL.
d58 5
a62 5
   * Lack of permanent internal identifiers for data. e.g. they may rely on database primary keys that are changed during database migrations but which don't effect their internal working processes - a spreadsheet mentality to data.
   * Lack of the awareness of the primary benefit to the data supplier of tagging data with GUIDs i.e. the ability of users to cite their sources and give credit even when data from multiple sources has been used in an analysis.
   * Confusion over GUID standards. There are a series of competing standards and there has been much open debate as to which to adopt. This even includes confusion within standards on how they should be implemented e.g. data return types.
   * Difficulty in implementing LSIDs. LSIDs require the addition of a special DNS rule to the name server that controls the institution's domain name. Data curators may not access to this name server or even know what a name server is let alone how to change it. This is a major barrier to LSIDs adoption.
   * Difficulty in implementing any resolvable identifier - even the URL to a web page. Many institutions have corporately managed web sites and it is no simple matter for data curators add database driven content even if they have the skills and applications/tools to hand.
d68 1
a68 1
   * Whenever you expose your data you should include GUIDs that can be resolved back to your internal locally unique IDs. Don't get hung up on the technology. If you can't manage LSIDs some type of URL that your institution can commit to maintaining for the foreseeable future is fine. In simple terms - every 'thing' you expose to the world should be represented by a web 'page'.
d84 1
a84 1
Even to keep a list of core TDWG concepts up to date, manage the consensus building process around new concepts and educate standards developers in how to integrate the ontology into their proposals is a very time consuming and therefore expensive process. Nobody has been resourced to do this work in 2008 and therefore it hasn't happened as it should. Unless some form of ontology manager is given the resources to curator this central resource then there is a danger that the expectations of interoperability will not be met.
d89 1
a89 1
   * If you are using XML use namespaces correctly so as to exploit other vocabularies. If can't do this publish a mapping to well know namespaces.
d97 1
a97 1
There were two important developments related with TAPIR in the last year. One of them is a new service ([[http://tapir.tdwg.org/tester][TapirTester]]) to test if a TAPIR provider is compliant with the current TAPIR specification. It can be used by those who need to implement new data provider software or by users of data provider software that want to check if their services are working properly. Although TapirTester does not include all possible tests that can be performed, it covers most aspects of the protocol, which makes it an important quality control tool. The new service is available both as a web interface and as a web service:
d109 1
a109 1
   * or are do not have the ability to install wrapper software on an accessible web server.
d121 1
a121 1
   * If you want to expose data to a particular project follow that particular projects current recommendations. It is the role of the TAG to make recommendations to projects not to individual data suppliers.
d123 1
a123 1
   * Even if you exchanging plain XML documents using TAPIR you should make sure you use GUIDs and map to the TDWG Ontology where ever possible.
d128 1
a128 1
%SEARCH{"%TOPIC%" excludetopic="%TOPIC%" header="*Linking Topics*" format="   * $topic" nosearch="on" nototal="on" }%
@


1.10
log
@none
@
text
@d1 1
a1 1
%META:TOPICINFO{author="RogerHyam" date="1223892226" format="1.1" version="1.10"}%
d118 1
a118 3
There has been some discussion on REST ([[http://en.wikipedia.org/wiki/Representational_State_Transfer][Representational State Transfer]]) web services. REST is a style of architecture rather than a specific protocol. Both TAPIR and OAI-PMH could be regarded as RESTful services. Where the REST pattern is not matched by the TDWG architecture is the degree to which GUIDs are not all uniquely addressable using a universal syntax. Both LSIDs and DOIs make use of independent re

The GUID resolution through HTTP such as by using a LSID or DOI proxy also matches the RESTful pattern. The key element of 
d128 1
a128 1
%SEARCH{"%TOPIC%" excludetopic="%TOPIC%" header="*Linking Topics*" format="   * $topic" nosearch="on" nototal="on" }%@


1.9
log
@none
@
text
@d1 1
a1 1
%META:TOPICINFO{author="RogerHyam" date="1222784397" format="1.1" reprev="1.9" version="1.9"}%
d116 6
d130 1
a130 1
%SEARCH{"%TOPIC%" excludetopic="%TOPIC%" header="*Linking Topics*" format="   * $topic" nosearch="on" nototal="on" }%
@


1.8
log
@none
@
text
@d1 1
a1 1
%META:TOPICINFO{author="RogerHyam" date="1222768906" format="1.1" reprev="1.8" version="1.8"}%
d16 2
d43 1
a43 1
---++ Globaly Unique Identifiers (GUIDs)
@


1.7
log
@none
@
text
@d1 1
a1 1
%META:TOPICINFO{author="RogerHyam" date="1222704640" format="1.1" version="1.7"}%
d17 2
d23 1
a23 1
The reader is referred to the previous roadmaps (available on the TDWG website) for and explanation of a standards architecture.
d80 1
a80 1
The word ontology is a major challenge as it has dragged the community into hours of discussion concerning RDF, OWL, reification and inference. In so doing we lose sight of the tremendous benefits of having shared objects and their properties but eve
d82 1
a82 1
To keep a list of core TDWG concepts up to date, manage the consensus building process around new concepts and educate standards developers in how to integrate the ontology into their proposals is a very time consuming and therefore expensive process. Nobody has been resourced to do this work for the last year therefore it hasn't happened. Unless some form of ontology manager is given the paid time to do this the ontology will fail. 
d85 2
a86 2
   * Don't get hung up on complex talk of ontologies and inference especially if you are not designing your own exchange formats. The ontology should be thought of as a data dictionary for the community. 
   * If you are working on an exchange format don't make up new concepts if you can help it. Use existing ones for the TDWG ontology, IETF, W3C, Dublin Core etc or at least describe how your concepts match to these.
a88 1

d93 1
a93 3
There were two important developments related with TAPIR since the last report. One of them is a new service (TapirTester) to test if a TAPIR provider is compliant with the current TAPIR specification. It can be used by those who need to implement new data provider software or by users of data provider software that want to check if their services are working properly. Although TapirTester does not include all possible tests that can be performed, it covers most aspects of the protocol, which makes it an important quality control tool. The new service is available both as a web interface and as a web service:

http://tapir.tdwg.org/tester
d95 1
a95 1
The other development (TapirBuilder) facilitates the creation of TAPIR documents. TAPIR networks depend on specific documents to work: XML Schemas (that can be created by existing tools), output models and query templates. The last two documents are specific to TAPIR and sometimes it can be difficult to produce them by hand. TapirBuilder is a new online tool to help building such documents: 
d97 1
a97 1
http://tapir.tdwg.org/builder
d99 1
a99 3
A new format based on XML was also proposed to represent data abstraction layers for TAPIR (replacing the previous CNS configuration files using key-value pairs in plain text). An index containing some of the existing data abstraction layers is available:

http://rs.tdwg.org/tapir/cns/index.xml
d103 1
a103 1
---++++ Comments
d105 4
a108 1
Recently we discussed the need to be able to "discover" existing TAPIR models that people develop as these would be useful for other people to reuse, when appropriate.  At present there is a Concept Index (http://rs.tdwg.org/tapir/cns/index.xml) - do we need something similar for TAPIR models and templates.
d110 1
a110 5
-- Main.KevinRichards - 08 Aug 2008

---+++ Delimited Files

While harvesting flat (DwC style) data for the GBIF data portal it became apparent that the communications using existing TDWG protocols were very verbose, resulting in a large amount of network traffic and database activity to do something that could be achieved in a more simple manner.  Additionally, there are provider who have either a) too large a dataset to effectively harvest the full amount (months of work) or b) technical limitations while installing existing wrapper software.  For these reasons, it has been decided to support simple delimitted files, that represent the full dataset, and are produced on the provider side (by simple database exporting) and compressed for transfer.  Extensions, like the existing DwC extensions will be supported by a file per extension, whereby the row in the extension file references the identifier of the core file, thereby allowing for "many to one" style extensions.
d112 1
d115 1
a115 1
   * If you want to expose data to a particular project follow that projects particular recommendations.
d117 1
d119 1
a119 3
   * If you are making the recommendations and it is likely that some or all of your data suppliers will not be able to set up and run web services consider participating with Tim and Markus in development of a CSV format.


d122 1
a122 1
%SEARCH{"%TOPIC%" excludetopic="%TOPIC%" header="*Linking Topics*" format="   * $topic" nosearch="on" nototal="on" }%@


1.6
log
@none
@
text
@d1 1
a1 1
%META:TOPICINFO{author="RogerHyam" date="1222696748" format="1.1" version="1.6"}%
d68 1
a68 1
Ontology is a loaded term...
d70 5
d77 3
@


1.5
log
@none
@
text
@d1 1
a1 1
%META:TOPICINFO{author="RogerHyam" date="1222691387" format="1.1" reprev="1.5" version="1.5"}%
d104 4
d118 1
a118 1
%SEARCH{"%TOPIC%" excludetopic="%TOPIC%" header="*Linking Topics*" format="   * $topic" nosearch="on" nototal="on" }%
@


1.4
log
@none
@
text
@d1 1
a1 1
%META:TOPICINFO{author="RogerHyam" date="1222427485" format="1.1" reprev="1.4" version="1.4"}%
d39 10
a48 1
---++ GUIDs
a50 1
There is still a major hurdle to c
d52 13
a64 3
---+++ TAG GUID Recommendations
   * You must have working practises that maintain locally unique IDs on your data within your organisation. If you don't do this you will not be able to expose your data using globally unique IDs now or in the future.
   * Whenever you expose your data you should include GUIDs that can be resolved back to your internal locally unique IDs. Don't get hung up on the technology. If you can't manage LSIDs some type of URL that your institution can commit to maintaining for the foreseeable future is fine. Put another way - every 'thing' you expose to the world should be represented by a web 'page'.
d68 3
d77 1
@


1.3
log
@none
@
text
@d1 1
a1 1
%META:TOPICINFO{author="RenatoDeGiovanni" date="1220630818" format="1.1" version="1.3"}%
d39 9
d50 8
d82 6
a87 1
---++ GUIDs
d92 1
a92 1
%SEARCH{"%TOPIC%" excludetopic="%TOPIC%" header="*Linking Topics*" format="   * $topic" nosearch="on" nototal="on" }%@


1.2
log
@none
@
text
@d1 1
a1 1
%META:TOPICINFO{author="KevinRichards" date="1218158530" format="1.1" version="1.2"}%
d44 17
@


1.1
log
@none
@
text
@d1 1
a1 1
%META:TOPICINFO{author="RogerHyam" date="1217928551" format="1.1" reprev="1.1" version="1.1"}%
d43 5
d53 1
a53 1
%SEARCH{"%TOPIC%" excludetopic="%TOPIC%" header="*Linking Topics*" format="   * $topic" nosearch="on" nototal="on" }%
@
